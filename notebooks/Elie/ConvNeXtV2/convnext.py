# -*- coding: utf-8 -*-
"""convNext.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/19TACN7SnRoJ63uAw3-jMbfvy7U4PDufp
"""

from google.colab import drive
drive.mount('/content/drive')

import os
import pandas as pd
from PIL import Image
import torch
from torch.utils.data import DataLoader
from torchvision import transforms
import torch.nn as nn
import torch.optim as optim
import timm

# ---------------------------
# 1️⃣ Config / Hyperparameters
# ---------------------------
CSV_FILE = "/content/drive/MyDrive/streetSurfaceVis_v1_0.csv"
IMG_DIR = "/content/drive/MyDrive/s_1024"
BATCH_SIZE = 16
LR = 1e-4
EPOCHS_TYPE = 5
EPOCHS_QUALITY = 5
DEVICE = torch.device("cuda" if torch.cuda.is_available() else "cpu")

SURFACE_TYPE_MAP = {"asphalt":0,"concrete":1,"paving_stones":2,"unpaved":3,"sett":4}
SURFACE_QUALITY_MAP = {"excellent":1,"good":2,"intermediate":3,"bad":4,"very_bad":5}

# ---------------------------
# 2️⃣ Load CSV
# ---------------------------
df = pd.read_csv(CSV_FILE)

# ---------------------------
# 3️⃣ Preprocessing
# ---------------------------
model_tmp = timm.create_model("convnextv2_tiny", pretrained=True)
cfg = model_tmp.default_cfg
preprocess = transforms.Compose([
    transforms.Resize((224, 224)),
    transforms.ToTensor(),
    transforms.Normalize(mean=cfg['mean'], std=cfg['std'])
])
del model_tmp

# ---------------------------
# 4️⃣ Dataset Helpers
# ---------------------------
def load_item(idx):
    row = df.iloc[idx]
    img_path = os.path.join(IMG_DIR, str(row["mapillary_image_id"])+".jpg")
    image = Image.open(img_path).convert("RGB")
    t = SURFACE_TYPE_MAP[row["surface_type"]]
    q = SURFACE_QUALITY_MAP[row["surface_quality"]]
    return image, t, q

def collate_fn(batch):
    imgs, types, quals = zip(*batch)
    imgs = torch.stack([preprocess(img) for img in imgs])
    return imgs, torch.tensor(types), torch.tensor(quals, dtype=torch.float32)

def get_loader(indices):
    return DataLoader(indices, batch_size=BATCH_SIZE, shuffle=True,
                      collate_fn=lambda b: collate_fn([load_item(i) for i in b]))

# ---------------------------
# 5️⃣ Training Function
# ---------------------------
def train_model(model, loader, criterion, optimizer, epochs, task_type='classification'): # Added task_type parameter
    model.to(DEVICE)
    for epoch in range(epochs):
        model.train()
        running_loss = 0.0
        for images, types, quals in loader:
            images = images.to(DEVICE)
            # Use the correct target based on the task type
            if task_type == 'classification':
                targets = types.to(DEVICE)
            elif task_type == 'regression':
                targets = quals.to(DEVICE)
            else:
                raise ValueError("Invalid task_type. Must be 'classification' or 'regression'.")

            optimizer.zero_grad()
            outputs = model(images)
            loss = criterion(outputs, targets) # Use 'targets' here
            loss.backward()
            optimizer.step()
            running_loss += loss.item()
        print(f"Epoch {epoch+1}/{epochs}, Loss: {running_loss/len(loader):.4f}")

# ---------------------------
# 6️⃣ Step 1: Surface Type Classifier
# ---------------------------
model_type = timm.create_model("convnextv2_tiny", pretrained=True)
in_feat = model_type.head.fc.in_features
model_type.head.fc = nn.Linear(in_feat, len(SURFACE_TYPE_MAP))
criterion_type = nn.CrossEntropyLoss()
optimizer_type = optim.AdamW(model_type.parameters(), lr=LR)

existing_indices = [i for i in range(len(df))
                    if os.path.exists(os.path.join(IMG_DIR, str(df.iloc[i]["mapillary_image_id"])+".jpg"))]

train_model(model_type, get_loader(existing_indices), criterion_type, optimizer_type, EPOCHS_TYPE, task_type='classification') # Added task_type

# ---------------------------
# 7️⃣ Step 2: Surface Quality Regressors
# ---------------------------
type_to_indices = {k: df[df["surface_type"]==k].index.tolist() for k in SURFACE_TYPE_MAP}
quality_models = {}
criterion_quality = nn.MSELoss()

for type_name, indices in type_to_indices.items():
    # Filter indices to include only those with existing image files
    existing_indices_for_type = [i for i in indices
                                 if os.path.exists(os.path.join(IMG_DIR, str(df.iloc[i]["mapillary_image_id"])+".jpg"))]
    print(f"Training quality regressor for {type_name} ({len(existing_indices_for_type)} samples)")
    if len(existing_indices_for_type) > 0: # Added check for empty list
        model_q = timm.create_model("convnextv2_tiny", pretrained=True)
        in_feat = model_q.head.fc.in_features
        model_q.head.fc = nn.Linear(in_feat,1)
        optimizer_q = optim.AdamW(model_q.parameters(), lr=LR)
        train_model(model_q, get_loader(existing_indices_for_type), criterion_quality, optimizer_q, EPOCHS_QUALITY, task_type='regression') # Added task_type
        quality_models[type_name] = model_q
    else:
        print(f"No existing images found for {type_name}. Skipping training for this type.")

# ---------------------------
# 8️⃣ Inference Pipeline
# ---------------------------
def predict_surface(image):
    model_type.eval()
    x = preprocess(image).unsqueeze(0).to(DEVICE)
    with torch.no_grad():
        type_idx = torch.argmax(model_type(x), dim=1).item()
        type_str = list(SURFACE_TYPE_MAP.keys())[type_idx]
        quality_score = quality_models[type_str](x).item()
    return type_str, quality_score

# Example usage
img = Image.open(os.path.join(IMG_DIR,"1068388274103113.jpg")).convert("RGB")
surface_type, surface_quality = predict_surface(img)
print(surface_type, surface_quality)

