# -*- coding: utf-8 -*-
"""resnet.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1fFTN4drQGd2B3STY7_WnoXWBhiZOQCw1
"""

import os
import torch
import torch.nn as nn
import torch.optim as optim
from torch.utils.data import Dataset, DataLoader
from torchvision import models, transforms
from PIL import Image
from google.colab import drive
import pandas as pd
from matplotlib import pyplot as plt

drive.mount('/content/drive')
csv_path = '/content/drive/MyDrive/streetSurfaceVis_v1_0.csv'  # Update with your CSV path
img_folder = '/content/drive/MyDrive/s_1024'   # Folder containing all images

SURFACE_TYPE_MAP = {"asphalt":0,"concrete":1,"paving_stones":2,"unpaved":3,"sett":4}
SURFACE_QUALITY_MAP = {"excellent":1,"good":2,"intermediate":3,"bad":4,"very_bad":5}

class SurfaceDataset(Dataset):
    def __init__(self, csv_file, img_folder, transform=None):
        self.df = pd.read_csv(csv_file)
        self.img_folder = img_folder
        self.transform = transform
        # Filter dataframe to only include images that exist in the folder
        self.df = self.df[self.df['mapillary_image_id'].apply(lambda x: os.path.exists(os.path.join(self.img_folder, str(x) + ".jpg")))].reset_index(drop=True)

    def __len__(self):
        return len(self.df)

    def __getitem__(self, idx):
        row = self.df.iloc[idx]
        img_path = os.path.join(self.img_folder, str(row['mapillary_image_id']) + ".jpg")
        img = Image.open(img_path).convert('RGB')
        if self.transform:
            img = self.transform(img)
        main_label = SURFACE_TYPE_MAP[row['surface_type']]
        sub_label = SURFACE_QUALITY_MAP[row['surface_quality']]
        return img, (main_label, sub_label)

transform = transforms.Compose([
    transforms.Resize((224,224)),
    transforms.ToTensor(),
    transforms.Normalize([0.485,0.456,0.406], [0.229,0.224,0.225])
])

dataset = SurfaceDataset(csv_path, img_folder, transform=transform)
dataloader = DataLoader(dataset, batch_size=16, shuffle=True)

device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')

class DoubleHeadResNet(nn.Module):
    def __init__(self, num_main, num_sub):
        super().__init__()
        self.backbone = models.resnet18(pretrained=True)
        in_feat = self.backbone.fc.in_features
        self.backbone.fc = nn.Identity()
        self.fc_main = nn.Linear(in_feat, num_main)
        self.fc_sub = nn.Linear(in_feat, num_sub)
    def forward(self, x):
        feat = self.backbone(x)
        return self.fc_main(feat), self.fc_sub(feat)

model = DoubleHeadResNet(num_main=len(SURFACE_TYPE_MAP), num_sub=len(SURFACE_QUALITY_MAP)).to(device)

criterion = nn.CrossEntropyLoss()
optimizer = optim.Adam(model.parameters(), lr=1e-4)

model.train()
for images, (main_labels, sub_labels) in dataloader:
    images = images.to(device)
    main_labels = main_labels.to(device)
    sub_labels = sub_labels.to(device) - 1 # Subtract 1 to make sub_labels 0-indexed

    optimizer.zero_grad()
    main_out, sub_out = model(images)
    loss = criterion(main_out, main_labels) + criterion(sub_out, sub_labels)
    loss.backward()
    optimizer.step()

sample_img_id = dataset.df.iloc[0]['mapillary_image_id']
img_path = os.path.join(img_folder, str(sample_img_id) + ".jpg")
img = Image.open(img_path).convert('RGB')
img_t = transform(img).unsqueeze(0).to(device)

model.eval()
with torch.no_grad():
    main_out, sub_out = model(img_t)
    main_idx = main_out.argmax(dim=1).item()
    sub_idx = sub_out.argmax(dim=1).item()

main_class = [k for k,v in SURFACE_TYPE_MAP.items() if v==main_idx][0]
sub_class = [k for k,v in SURFACE_QUALITY_MAP.items() if v==sub_idx][0]

print("Predicted surface type:", main_class)
print("Predicted surface quality:", sub_class)

plt.imshow(img)
plt.title(f"Type: {main_class}, Quality: {sub_class}")
plt.axis('off')
plt.show()

